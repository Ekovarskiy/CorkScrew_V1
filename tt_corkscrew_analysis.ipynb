{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TT Image Corkscrew Artifact Removal (EDA + Benchmark + Report)\n",
        "\n",
        "Workflow:\n",
        "1. Load TT matrix from XLSX (expected around `(11999, 180)`).\n",
        "2. Run EDA and spectral stripe-orientation analysis.\n",
        "3. Execute 4 candidate denoising/de-striping methods.\n",
        "4. Score methods and select a best candidate.\n",
        "5. Export artifacts in `outputs/` including:\n",
        "   - figures + CSV\n",
        "   - markdown report with embedded images\n",
        "   - PDF report\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Iterable\n",
        "import io\n",
        "import textwrap\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from scipy import ndimage, signal\n",
        "from scipy.fft import fft2, ifft2, fftshift, ifftshift\n",
        "from scipy.ndimage import median_filter, gaussian_filter1d\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "ROOT = Path(\".\")\n",
        "OUTPUT_DIR = ROOT / \"outputs\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "EXPECTED_SHAPE = (11999, 180)\n",
        "\n",
        "FIG_EDA = OUTPUT_DIR / \"01_eda_image_hist.png\"\n",
        "FIG_FFT = OUTPUT_DIR / \"02_fft_raw.png\"\n",
        "FIG_METHODS = OUTPUT_DIR / \"03_method_comparison.png\"\n",
        "FIG_METRICS = OUTPUT_DIR / \"04_metrics.png\"\n",
        "CSV_METRICS = OUTPUT_DIR / \"method_metrics.csv\"\n",
        "MD_REPORT = OUTPUT_DIR / \"report.md\"\n",
        "PDF_REPORT = OUTPUT_DIR / \"report.pdf\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def build_tt_candidates(root: Path) -> list[Path]:\n",
        "    \"\"\"Ordered TT candidate list (common names first, then fuzzy TT-like names).\"\"\"\n",
        "    fixed = [\n",
        "        root / \"TT.xlsx\",\n",
        "        root / \"tt.xlsx\",\n",
        "        root / \"data/TT.xlsx\",\n",
        "        root / \"data/tt.xlsx\",\n",
        "    ]\n",
        "    fuzzy = []\n",
        "    for p in root.rglob(\"*.xlsx\"):\n",
        "        stem = p.stem.lower()\n",
        "        if \"tt\" in stem and p not in fixed:\n",
        "            fuzzy.append(p)\n",
        "    return fixed + sorted(fuzzy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def load_tt_data(candidates: Iterable[Path]) -> tuple[np.ndarray, str, str]:\n",
        "    \"\"\"Load TT from XLSX; if unavailable, use synthetic demo data.\"\"\"\n",
        "    for path in candidates:\n",
        "        if path.exists():\n",
        "            df = pd.read_excel(path, header=None)\n",
        "            arr = df.to_numpy(dtype=float)\n",
        "            return arr, f\"Loaded real TT from: {path}\", \"real\"\n",
        "\n",
        "    warnings.warn(\n",
        "        \"No TT.xlsx-like file found. Running on synthetic demo data.\",\n",
        "        RuntimeWarning,\n",
        "    )\n",
        "    n_depth, n_theta = 2500, 180\n",
        "    z = np.arange(n_depth)[:, None]\n",
        "    theta = np.linspace(0, 2 * np.pi, n_theta, endpoint=False)[None, :]\n",
        "\n",
        "    geology = (\n",
        "        0.45 * np.sin(2.2 * theta + 0.0017 * z)\n",
        "        + 0.20 * np.sin(7.5 * theta - 0.0006 * z)\n",
        "        + 0.18 * np.cos(0.0011 * z)\n",
        "    )\n",
        "    corkscrew = 0.38 * np.sin(17.0 * theta + 0.024 * z)\n",
        "    noise = 0.08 * np.random.default_rng(42).normal(size=(n_depth, n_theta))\n",
        "    arr = geology + corkscrew + noise\n",
        "    return arr, \"Loaded synthetic demonstration TT data\", \"synthetic\"\n",
        "\n",
        "\n",
        "TT_CANDIDATES = build_tt_candidates(ROOT)\n",
        "tt, load_message, data_kind = load_tt_data(TT_CANDIDATES)\n",
        "print(load_message)\n",
        "print(\"TT shape:\", tt.shape)\n",
        "if tt.shape != EXPECTED_SHAPE:\n",
        "    print(f\"Warning: expected shape {EXPECTED_SHAPE}, got {tt.shape}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def nan_safe_stats(img: np.ndarray) -> dict[str, float]:\n",
        "    finite = img[np.isfinite(img)]\n",
        "    return {\n",
        "        \"count\": float(finite.size),\n",
        "        \"min\": float(np.min(finite)),\n",
        "        \"max\": float(np.max(finite)),\n",
        "        \"mean\": float(np.mean(finite)),\n",
        "        \"std\": float(np.std(finite)),\n",
        "        \"nan_ratio\": float(np.mean(~np.isfinite(img))),\n",
        "    }\n",
        "\n",
        "\n",
        "def normalize_image(img: np.ndarray) -> np.ndarray:\n",
        "    q1, q99 = np.nanpercentile(img, [1, 99])\n",
        "    return np.clip((img - q1) / (q99 - q1 + 1e-12), 0, 1)\n",
        "\n",
        "\n",
        "def spectrum(img: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
        "    clean = np.nan_to_num(img, nan=np.nanmedian(img))\n",
        "    f = fftshift(fft2(clean))\n",
        "    mag = np.log1p(np.abs(f))\n",
        "    return f, mag\n",
        "\n",
        "\n",
        "def estimate_stripe_angle_from_fft(img: np.ndarray) -> float:\n",
        "    \"\"\"Estimate stripe angle in image domain using weighted FFT orientation.\"\"\"\n",
        "    _, mag = spectrum(img)\n",
        "    h, w = mag.shape\n",
        "    cy, cx = h // 2, w // 2\n",
        "\n",
        "    yy, xx = np.indices((h, w))\n",
        "    dy = yy - cy\n",
        "    dx = xx - cx\n",
        "    rr = np.sqrt(dy**2 + dx**2)\n",
        "\n",
        "    annulus = (rr > min(h, w) * 0.08) & (rr < min(h, w) * 0.45)\n",
        "    weights = np.where(annulus, mag, 0.0)\n",
        "\n",
        "    sxx = np.sum(weights * dx * dx)\n",
        "    syy = np.sum(weights * dy * dy)\n",
        "    sxy = np.sum(weights * dx * dy)\n",
        "    angle_freq = 0.5 * np.degrees(np.arctan2(2 * sxy, sxx - syy))\n",
        "\n",
        "    stripe_angle = (angle_freq + 90.0) % 180.0\n",
        "    return float(stripe_angle)\n",
        "\n",
        "\n",
        "stats = nan_safe_stats(tt)\n",
        "img_norm = normalize_image(tt)\n",
        "f_raw, mag_raw = spectrum(tt)\n",
        "stripe_angle = estimate_stripe_angle_from_fft(tt)\n",
        "print(f\"Estimated corkscrew stripe angle: {stripe_angle:.2f}°\")\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
        "ax[0].imshow(tt, aspect=\"auto\", cmap=\"viridis\")\n",
        "ax[0].set_title(\"Raw TT\")\n",
        "ax[0].set_xlabel(\"Angle index\")\n",
        "ax[0].set_ylabel(\"Depth index\")\n",
        "\n",
        "ax[1].imshow(img_norm, aspect=\"auto\", cmap=\"viridis\")\n",
        "ax[1].set_title(\"Contrast-normalized TT\")\n",
        "ax[1].set_xlabel(\"Angle index\")\n",
        "ax[1].set_ylabel(\"Depth index\")\n",
        "\n",
        "ax[2].hist(tt[np.isfinite(tt)].ravel(), bins=120, color=\"steelblue\")\n",
        "ax[2].set_title(\"Value histogram\")\n",
        "ax[2].set_xlabel(\"TT value\")\n",
        "ax[2].set_ylabel(\"Count\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_EDA, dpi=170)\n",
        "plt.close(fig)\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "plt.imshow(mag_raw, cmap=\"magma\", aspect=\"auto\")\n",
        "plt.title(\"2D FFT log-magnitude (TT)\")\n",
        "plt.xlabel(\"freq_theta\")\n",
        "plt.ylabel(\"freq_depth\")\n",
        "plt.colorbar(label=\"log(1+|F|)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_FFT, dpi=170)\n",
        "plt.close(fig)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Candidate methods\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fft_notch_filter(img: np.ndarray, top_k: int = 8, notch_sigma: float = 3.0) -> np.ndarray:\n",
        "    f = fftshift(fft2(img))\n",
        "    mag = np.abs(f)\n",
        "    h, w = img.shape\n",
        "    cy, cx = h // 2, w // 2\n",
        "\n",
        "    yy, xx = np.indices((h, w))\n",
        "    rr = np.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n",
        "\n",
        "    search = mag.copy()\n",
        "    search[rr < min(h, w) * 0.08] = 0.0\n",
        "\n",
        "    peak_idx = np.argpartition(search.ravel(), -top_k)[-top_k:]\n",
        "    peaks = np.column_stack(np.unravel_index(peak_idx, search.shape))\n",
        "\n",
        "    H = np.ones_like(img, dtype=float)\n",
        "    for py, px in peaks:\n",
        "        for qy, qx in [(py, px), (2 * cy - py, 2 * cx - px)]:\n",
        "            d2 = (yy - qy) ** 2 + (xx - qx) ** 2\n",
        "            H *= (1 - np.exp(-d2 / (2 * notch_sigma**2)))\n",
        "\n",
        "    return np.real(ifft2(ifftshift(f * H)))\n",
        "\n",
        "\n",
        "\n",
        "def directional_median_filter(img: np.ndarray, angle_deg: float, stripe_width: int = 11) -> np.ndarray:\n",
        "    rot = ndimage.rotate(img, -angle_deg, reshape=False, order=1, mode=\"reflect\")\n",
        "    filt = median_filter(rot, size=(1, stripe_width), mode=\"reflect\")\n",
        "    return ndimage.rotate(filt, angle_deg, reshape=False, order=1, mode=\"reflect\")\n",
        "\n",
        "\n",
        "\n",
        "def estimate_row_shifts(img: np.ndarray, max_shift: int = 25, smooth_sigma: float = 12) -> np.ndarray:\n",
        "    n_depth, n_theta = img.shape\n",
        "    shifts = np.zeros(n_depth, dtype=float)\n",
        "    prev = img[0] - np.mean(img[0])\n",
        "\n",
        "    lags = np.arange(-n_theta + 1, n_theta)\n",
        "    valid = (lags >= -max_shift) & (lags <= max_shift)\n",
        "\n",
        "    for i in range(1, n_depth):\n",
        "        cur = img[i] - np.mean(img[i])\n",
        "        corr = signal.correlate(prev, cur, mode=\"full\", method=\"fft\")\n",
        "        lag = lags[valid][np.argmax(corr[valid])]\n",
        "        shifts[i] = shifts[i - 1] + lag\n",
        "        prev = cur\n",
        "\n",
        "    return gaussian_filter1d(shifts, sigma=smooth_sigma)\n",
        "\n",
        "\n",
        "\n",
        "def helical_demodulation_filter(img: np.ndarray) -> np.ndarray:\n",
        "    shifts = estimate_row_shifts(img)\n",
        "\n",
        "    aligned = np.empty_like(img)\n",
        "    for i, s in enumerate(shifts):\n",
        "        aligned[i] = np.roll(img[i], int(np.round(-s)))\n",
        "\n",
        "    aligned_smooth = gaussian_filter1d(aligned, sigma=2.0, axis=1, mode=\"wrap\")\n",
        "\n",
        "    restored = np.empty_like(img)\n",
        "    for i, s in enumerate(shifts):\n",
        "        restored[i] = np.roll(aligned_smooth[i], int(np.round(s)))\n",
        "    return restored\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RPCAConfig:\n",
        "    lam: float | None = None\n",
        "    mu: float | None = None\n",
        "    max_iter: int = 100\n",
        "    tol: float = 1e-5\n",
        "    depth_stride: int = 4\n",
        "\n",
        "\n",
        "\n",
        "def _soft_threshold(x: np.ndarray, tau: float) -> np.ndarray:\n",
        "    return np.sign(x) * np.maximum(np.abs(x) - tau, 0.0)\n",
        "\n",
        "\n",
        "\n",
        "def robust_pca_lowrank(img: np.ndarray, cfg: RPCAConfig = RPCAConfig()) -> np.ndarray:\n",
        "    ds = max(1, int(cfg.depth_stride))\n",
        "    M_full = img.astype(float)\n",
        "    M = M_full[::ds]\n",
        "    m, n = M.shape\n",
        "\n",
        "    lam = cfg.lam if cfg.lam is not None else 1.0 / np.sqrt(max(m, n))\n",
        "    mu = cfg.mu if cfg.mu is not None else (m * n) / (4.0 * np.sum(np.abs(M)) + 1e-12)\n",
        "\n",
        "    L = np.zeros_like(M)\n",
        "    S = np.zeros_like(M)\n",
        "    Y = np.zeros_like(M)\n",
        "    normM = np.linalg.norm(M, ord=\"fro\") + 1e-12\n",
        "\n",
        "    for _ in range(cfg.max_iter):\n",
        "        U, s, Vt = np.linalg.svd(M - S + (1 / mu) * Y, full_matrices=False)\n",
        "        s_sh = np.maximum(s - 1 / mu, 0)\n",
        "        rank = np.sum(s_sh > 0)\n",
        "\n",
        "        if rank > 0:\n",
        "            L = (U[:, :rank] * s_sh[:rank]) @ Vt[:rank]\n",
        "        else:\n",
        "            L = np.zeros_like(M)\n",
        "\n",
        "        S = _soft_threshold(M - L + (1 / mu) * Y, lam / mu)\n",
        "        residual = M - L - S\n",
        "        Y = Y + mu * residual\n",
        "\n",
        "        if np.linalg.norm(residual, ord=\"fro\") / normM < cfg.tol:\n",
        "            break\n",
        "\n",
        "    idx_ds = np.arange(0, M_full.shape[0], ds)\n",
        "    idx_full = np.arange(M_full.shape[0])\n",
        "\n",
        "    L_full = np.empty_like(M_full)\n",
        "    for j in range(M_full.shape[1]):\n",
        "        L_full[:, j] = np.interp(idx_full, idx_ds, L[:, j])\n",
        "\n",
        "    return L_full\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark and selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def stripe_energy_metric(img: np.ndarray, stripe_angle_deg: float, bandwidth_deg: float = 12.0) -> float:\n",
        "    _, mag = spectrum(img)\n",
        "    h, w = mag.shape\n",
        "    cy, cx = h // 2, w // 2\n",
        "\n",
        "    yy, xx = np.indices((h, w))\n",
        "    dy = yy - cy\n",
        "    dx = xx - cx\n",
        "    rr = np.sqrt(dy**2 + dx**2)\n",
        "\n",
        "    ang = (np.degrees(np.arctan2(dy, dx)) + 180.0) % 180.0\n",
        "    stripe_freq_angle = (stripe_angle_deg - 90.0) % 180.0\n",
        "    d_ang = np.minimum(np.abs(ang - stripe_freq_angle), 180.0 - np.abs(ang - stripe_freq_angle))\n",
        "\n",
        "    mask = (rr > min(h, w) * 0.08) & (d_ang <= bandwidth_deg)\n",
        "    return float(np.mean(mag[mask]))\n",
        "\n",
        "\n",
        "\n",
        "def preservation_metric(raw: np.ndarray, filt: np.ndarray) -> float:\n",
        "    gx0, gz0 = np.gradient(raw, axis=1), np.gradient(raw, axis=0)\n",
        "    gxf, gzf = np.gradient(filt, axis=1), np.gradient(filt, axis=0)\n",
        "\n",
        "    v0 = np.concatenate([gx0.ravel(), gz0.ravel()]).astype(float)\n",
        "    vf = np.concatenate([gxf.ravel(), gzf.ravel()]).astype(float)\n",
        "\n",
        "    v0 -= v0.mean()\n",
        "    vf -= vf.mean()\n",
        "    denom = np.linalg.norm(v0) * np.linalg.norm(vf) + 1e-12\n",
        "    return float(np.dot(v0, vf) / denom)\n",
        "\n",
        "\n",
        "results: dict[str, np.ndarray] = {\"raw\": tt}\n",
        "results[\"fft_notch\"] = fft_notch_filter(tt, top_k=8, notch_sigma=3.0)\n",
        "results[\"directional_median\"] = directional_median_filter(tt, stripe_angle, stripe_width=11)\n",
        "results[\"helical_demod\"] = helical_demodulation_filter(tt)\n",
        "results[\"rpca_lowrank\"] = robust_pca_lowrank(tt, RPCAConfig(max_iter=100, tol=1e-5, depth_stride=4))\n",
        "\n",
        "metrics = []\n",
        "base_stripe = stripe_energy_metric(results[\"raw\"], stripe_angle)\n",
        "\n",
        "for name, img in results.items():\n",
        "    if name == \"raw\":\n",
        "        continue\n",
        "    stripe = stripe_energy_metric(img, stripe_angle)\n",
        "    stripe_reduction = (base_stripe - stripe) / (base_stripe + 1e-12)\n",
        "    preserve = preservation_metric(results[\"raw\"], img)\n",
        "    score = 0.65 * stripe_reduction + 0.35 * preserve\n",
        "    metrics.append((name, stripe, stripe_reduction, preserve, score))\n",
        "\n",
        "metrics_df = pd.DataFrame(\n",
        "    metrics,\n",
        "    columns=[\"method\", \"stripe_energy\", \"stripe_reduction\", \"preservation\", \"score\"],\n",
        ").sort_values(\"score\", ascending=False)\n",
        "\n",
        "best_method = str(metrics_df.iloc[0][\"method\"])\n",
        "print(\"Selected best method:\", best_method)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10), sharex=True, sharey=True)\n",
        "plot_order = [\"raw\", \"fft_notch\", \"directional_median\", \"helical_demod\", \"rpca_lowrank\"]\n",
        "for ax, name in zip(axes.ravel(), plot_order):\n",
        "    ax.imshow(results[name], aspect=\"auto\", cmap=\"viridis\")\n",
        "    ax.set_title(name)\n",
        "    ax.set_xlabel(\"Angle index\")\n",
        "    ax.set_ylabel(\"Depth index\")\n",
        "\n",
        "axes.ravel()[-1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_METHODS, dpi=170)\n",
        "plt.close(fig)\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "ax1.bar(metrics_df[\"method\"], metrics_df[\"stripe_reduction\"], alpha=0.75)\n",
        "ax1.set_ylabel(\"Stripe reduction (higher better)\")\n",
        "ax1.tick_params(axis=\"x\", rotation=20)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(metrics_df[\"method\"], metrics_df[\"preservation\"], \"o-r\")\n",
        "ax2.set_ylabel(\"Structure preservation (higher better)\")\n",
        "\n",
        "plt.title(\"Method benchmark\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_METRICS, dpi=170)\n",
        "plt.close(fig)\n",
        "\n",
        "metrics_df.to_csv(CSV_METRICS, index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Report writing (Markdown + PDF)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def dataframe_to_markdown(df: pd.DataFrame) -> str:\n",
        "    try:\n",
        "        return df.to_markdown(index=False, floatfmt=\".5f\")\n",
        "    except Exception:\n",
        "        # fallback if tabulate is not available\n",
        "        return df.to_csv(index=False)\n",
        "\n",
        "\n",
        "\n",
        "def write_markdown_report(\n",
        "    out_path: Path,\n",
        "    data_kind: str,\n",
        "    load_message: str,\n",
        "    shape: tuple[int, int],\n",
        "    stripe_angle: float,\n",
        "    stats: dict[str, float],\n",
        "    metrics_df: pd.DataFrame,\n",
        "    best_method: str,\n",
        ") -> None:\n",
        "    table_md = dataframe_to_markdown(metrics_df)\n",
        "\n",
        "    text = f\"\"\"\\\n",
        "# TT Corkscrew Artifact Removal Report\n",
        "\n",
        "## 1) Data summary\n",
        "- Source: **{data_kind}**\n",
        "- Loader note: {load_message}\n",
        "- Shape used: `{shape}`\n",
        "- Expected nominal shape: `{EXPECTED_SHAPE}`\n",
        "- NaN ratio: `{stats['nan_ratio']:.6f}`\n",
        "- Value range: `{stats['min']:.5f}` to `{stats['max']:.5f}`\n",
        "- Mean ± std: `{stats['mean']:.5f}` ± `{stats['std']:.5f}`\n",
        "\n",
        "## 2) EDA\n",
        "- Estimated dominant corkscrew stripe angle (from FFT): **{stripe_angle:.2f}°**\n",
        "\n",
        "![EDA overview](01_eda_image_hist.png)\n",
        "\n",
        "![Raw FFT spectrum](02_fft_raw.png)\n",
        "\n",
        "## 3) Methods evaluated\n",
        "1. FFT notch suppression\n",
        "2. Directional median filtering\n",
        "3. Helical demodulation (row-shift alignment)\n",
        "4. Robust PCA low-rank reconstruction (depth-downsampled)\n",
        "\n",
        "## 4) Quantitative benchmark\n",
        "Scoring formula:\n",
        "\n",
        "`score = 0.65 * stripe_reduction + 0.35 * preservation`\n",
        "\n",
        "{table_md}\n",
        "\n",
        "![Method visual comparison](03_method_comparison.png)\n",
        "\n",
        "![Metric comparison](04_metrics.png)\n",
        "\n",
        "## 5) Final selection\n",
        "Selected best method: **{best_method}**\n",
        "\n",
        "## 6) Notes\n",
        "- Results depend on interval/geology; validate best method on several intervals.\n",
        "- After TT validation, reuse this benchmark on AMP for cross-channel consistency.\n",
        "\"\"\"\n",
        "    out_path.write_text(textwrap.dedent(text), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "\n",
        "def _render_wrapped_text_page(pdf: PdfPages, title: str, body: str, fontsize: int = 10) -> None:\n",
        "    fig = plt.figure(figsize=(8.27, 11.69))  # A4 portrait in inches\n",
        "    fig.patch.set_facecolor(\"white\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    wrapped_lines = []\n",
        "    for line in body.splitlines():\n",
        "        wrapped = textwrap.wrap(line, width=100) or [\"\"]\n",
        "        wrapped_lines.extend(wrapped)\n",
        "\n",
        "    text = f\"{title}\\n\\n\" + \"\\n\".join(wrapped_lines)\n",
        "    plt.text(0.05, 0.97, text, va=\"top\", ha=\"left\", fontsize=fontsize, family=\"monospace\")\n",
        "    pdf.savefig(fig, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "def _add_image_page(pdf: PdfPages, image_path: Path, title: str) -> None:\n",
        "    if not image_path.exists():\n",
        "        return\n",
        "    img = mpimg.imread(image_path)\n",
        "    fig = plt.figure(figsize=(8.27, 11.69))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "    pdf.savefig(fig, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "def markdown_to_pdf(markdown_path: Path, pdf_path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Create a readable PDF report without external dependencies:\n",
        "    - page 1..n: markdown text (wrapped)\n",
        "    - next pages: embedded figure images\n",
        "    \"\"\"\n",
        "    md_text = markdown_path.read_text(encoding=\"utf-8\")\n",
        "\n",
        "    # split markdown text into chunks for multiple pages\n",
        "    lines = md_text.splitlines()\n",
        "    chunk_size = 70\n",
        "    chunks = [\"\\n\".join(lines[i : i + chunk_size]) for i in range(0, len(lines), chunk_size)]\n",
        "\n",
        "    with PdfPages(pdf_path) as pdf:\n",
        "        for idx, chunk in enumerate(chunks, start=1):\n",
        "            _render_wrapped_text_page(pdf, title=f\"TT Report (Text) - page {idx}\", body=chunk, fontsize=9)\n",
        "\n",
        "        _add_image_page(pdf, FIG_EDA, \"EDA overview\")\n",
        "        _add_image_page(pdf, FIG_FFT, \"FFT spectrum\")\n",
        "        _add_image_page(pdf, FIG_METHODS, \"Method visual comparison\")\n",
        "        _add_image_page(pdf, FIG_METRICS, \"Benchmark metrics\")\n",
        "\n",
        "\n",
        "write_markdown_report(\n",
        "    out_path=MD_REPORT,\n",
        "    data_kind=data_kind,\n",
        "    load_message=load_message,\n",
        "    shape=tt.shape,\n",
        "    stripe_angle=stripe_angle,\n",
        "    stats=stats,\n",
        "    metrics_df=metrics_df,\n",
        "    best_method=best_method,\n",
        ")\n",
        "\n",
        "markdown_to_pdf(MD_REPORT, PDF_REPORT)\n",
        "\n",
        "print(f\"Artifacts written to: {OUTPUT_DIR.resolve()}\")\n",
        "print(f\"- {FIG_EDA.name}\")\n",
        "print(f\"- {FIG_FFT.name}\")\n",
        "print(f\"- {FIG_METHODS.name}\")\n",
        "print(f\"- {FIG_METRICS.name}\")\n",
        "print(f\"- {CSV_METRICS.name}\")\n",
        "print(f\"- {MD_REPORT.name}\")\n",
        "print(f\"- {PDF_REPORT.name}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}